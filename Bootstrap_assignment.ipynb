{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bootstrap_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subro12/Assignments/blob/master/Bootstrap_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sNKZq4XrXQh",
        "colab_type": "text"
      },
      "source": [
        "# <font color='red'><b>Bootstrap assignment</b> </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAHap1Z3FZC-",
        "colab_type": "text"
      },
      "source": [
        "<b>There will be some functions that start with the word \"grader\" ex: grader_sampples(), grader_30().. etc, you should not change those function definition.\n",
        "\n",
        "Every Grader function has to return True.</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuxBq_bvrwh2",
        "colab_type": "text"
      },
      "source": [
        "<font color='blue'> <b>Importing packages</b> </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6ag91ijrQOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # importing numpy for numerical computation\n",
        "from sklearn.datasets import load_boston # here we are using sklearn's boston dataset\n",
        "from sklearn.metrics import mean_squared_error # importing mean_squared_error metric"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcHOsONTt1K_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "boston = load_boston()\n",
        "x=boston.data #independent variables\n",
        "y=boston.target #target variable"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pc1htEFYuLRj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89337e3d-3bf8-4928-fa61-52333a386c06"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQle3T_wuOa3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "affcf263-6787-4606-a98f-d29a44e06775"
      },
      "source": [
        "x[:5]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, 0.0000e+00, 5.3800e-01,\n",
              "        6.5750e+00, 6.5200e+01, 4.0900e+00, 1.0000e+00, 2.9600e+02,\n",
              "        1.5300e+01, 3.9690e+02, 4.9800e+00],\n",
              "       [2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
              "        6.4210e+00, 7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
              "        1.7800e+01, 3.9690e+02, 9.1400e+00],\n",
              "       [2.7290e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
              "        7.1850e+00, 6.1100e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
              "        1.7800e+01, 3.9283e+02, 4.0300e+00],\n",
              "       [3.2370e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
              "        6.9980e+00, 4.5800e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
              "        1.8700e+01, 3.9463e+02, 2.9400e+00],\n",
              "       [6.9050e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n",
              "        7.1470e+00, 5.4200e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n",
              "        1.8700e+01, 3.9690e+02, 5.3300e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEa_HqRZloH4",
        "colab_type": "text"
      },
      "source": [
        "## <font color='red'><b>Task 1</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ5q8IxHNRk3",
        "colab_type": "text"
      },
      "source": [
        "<font color='red'> <b>Step - 1</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJCFCaOzl7Mr",
        "colab_type": "text"
      },
      "source": [
        "*  <font color='blue'><b>Creating samples</b></font><br>\n",
        "    <b> Randomly create 30 samples from the whole boston data points</b>\n",
        "    *  Creating each sample: Consider any random 303(60% of 506) data points from whole data set and then replicate any 203 points from the sampled points\n",
        "    \n",
        "     For better understanding of this procedure lets check this examples, assume we have 10 data points [1,2,3,4,5,6,7,8,9,10], first we take 6 data points randomly , consider we have selected [4, 5, 7, 8, 9, 3] now we will replicate 4 points from [4, 5, 7, 8, 9, 3], consder they are [5, 8, 3,7] so our final sample will be [4, 5, 7, 8, 9, 3, 5, 8, 3,7]\n",
        "* <font color='blue'><b> Create 30 samples </b></font>\n",
        "    *  Note that as a part of the Bagging when you are taking the random samples <b>make sure each of the sample will have different set of columns</b><br>\n",
        "Ex: Assume we have 10 columns[1 ,2 ,3 ,4 ,5 ,6 ,7 ,8 ,9 ,10] for the first sample we will select [3, 4, 5, 9, 1, 2] and for the second sample  [7, 9, 1, 4, 5, 6, 2] and so on...\n",
        "Make sure each sample will have atleast 3 feautres/columns/attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUqFEBSvNjCa",
        "colab_type": "text"
      },
      "source": [
        "<font color='red'><b>Step - 2 </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqi9AhCYNq3Z",
        "colab_type": "text"
      },
      "source": [
        "<font color='blue'><b>Building High Variance Models on each of the sample and finding train MSE value</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lLBnZHXOFln",
        "colab_type": "text"
      },
      "source": [
        "*  Build a regression trees on each of 30 samples.\n",
        "*  Computed the predicted values of each data point(506 data points) in your corpus.\n",
        "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{30}\\sum_{k=1}^{30}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$\n",
        "*  Now calculate the $MSE =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kls23JLnSN23",
        "colab_type": "text"
      },
      "source": [
        "<font color='red'> <b>Step - 3 </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz2GchkGSWnh",
        "colab_type": "text"
      },
      "source": [
        "*  <font color='blue'><b>Calculating the OOB score </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGHkVV2kSibm",
        "colab_type": "text"
      },
      "source": [
        "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{k}\\sum_{\\text{k= model which was buit on samples not included } x^{i}}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.\n",
        "*  Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK860ocxTyoz",
        "colab_type": "text"
      },
      "source": [
        "# <font color='red'><b>Task 2</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dme-N6TUCrY",
        "colab_type": "text"
      },
      "source": [
        "*  <font color='blue'><b>Computing CI of OOB Score and Train MSE</b></font>\n",
        "  *   Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score </li>\n",
        "<li> After this we will have 35 Train MSE values and 35 OOB scores </li>\n",
        "<li> using these 35 values (assume like a sample) find the confidence intravels of MSE and OOB Score </li>\n",
        "<li> you need to report CI of MSE and CI of OOB Score </li>\n",
        "<li> Note: Refer the Central_Limit_theorem.ipynb to check how to find the confidence intravel</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6UcH1x9Uwrj",
        "colab_type": "text"
      },
      "source": [
        "# <font color='red'><b>Task 3</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOC_AgsLU7OH",
        "colab_type": "text"
      },
      "source": [
        "*  <font color='blue'><b>Given a single query point predict the price of house.</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYs5jSFdVILe",
        "colab_type": "text"
      },
      "source": [
        "Consider xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60] \n",
        "Predict the house price for this point as mentioned in the step 2 of Task 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6gxZEsFWm-8",
        "colab_type": "text"
      },
      "source": [
        "<br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2fHTdS_zpgG",
        "colab_type": "text"
      },
      "source": [
        "# <font color='blue'> <b>Task - 1</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0yGBuryOwHz",
        "colab_type": "text"
      },
      "source": [
        "<font color='blue'><b>Step - 1</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJXX8vf3z073",
        "colab_type": "text"
      },
      "source": [
        "*  <font color='blue'> <b>Creating samples</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSVaWG1F4uCZ",
        "colab_type": "text"
      },
      "source": [
        "<font color='Orange'><b>Algorithm</b></font>\n",
        "\n",
        "![alt text](https://i.imgur.com/BTVYXQ1.jpg/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_oWoN97BhDY",
        "colab_type": "text"
      },
      "source": [
        "*  <font color='blue'><b> Write code for generating samples</b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph_6D2SDzz7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generating_samples(input_data, target_data):\n",
        "  lnth = len(input_data)\n",
        "  selecting_rows = random.sample(range(0,lnth),int(lnth*.6))\n",
        "  replacing_rows = random.sample(selecting_rows,lnth-len(selecting_rows))\n",
        "  # print(replacing_rows,'\\n',len(replacing_rows))\n",
        "  col_length = len(input_data[0])\n",
        "  # print(col_length)\n",
        "  selecting_columns = sorted(random.sample(range(0,13),np.random.randint(3,12)))\n",
        "  #     print(\"selecting_rows-->\",selecting_rows)\n",
        "  #     print(\"selecting_columns-->\",selecting_columns)\n",
        "  sample_data = input_data[selecting_rows][:,selecting_columns]\n",
        "  target_of_sample_data = target_data[selecting_rows]\n",
        "  #     print(\"sample_data\")\n",
        "  #     print(sample_data)\n",
        "  replicated_sample_data = input_data[replacing_rows][:,selecting_columns]\n",
        "  #     print(\"replicated_sample_data\")\n",
        "  #     print(replicated_sample_data)\n",
        "  target_of_replicated_sample_data = target_data[replacing_rows]\n",
        "  final_sample_data = np.vstack((sample_data,replicated_sample_data))\n",
        "  final_target_data = np.vstack((target_of_sample_data.reshape(-1,1),target_of_replicated_sample_data.reshape(-1,1)))\n",
        "  return final_sample_data , final_target_data,selecting_rows,selecting_columns"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MivEQFlm7iOg",
        "colab_type": "text"
      },
      "source": [
        "<font color='cyan'> <b> Grader function - 1 </b> </fongt>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfLtY4Yrq0d-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVvuhNzm7uld",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "474638a5-5ff0-4e54-bf3b-34c17fa9625d"
      },
      "source": [
        "def grader_samples(a,b,c,d):\n",
        "    length = (len(a)==506  and len(b)==506)\n",
        "    sampled = (len(a)-len(set([str(i) for i in a]))==203)\n",
        "    rows_length = (len(c)==303)\n",
        "    column_length= (len(d)>=3)\n",
        "    assert(length and sampled and rows_length and column_length)\n",
        "    return True\n",
        "a,b,c,d = generating_samples(x, y)\n",
        "grader_samples(a,b,c,d)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4LSsmn4Jn2_",
        "colab_type": "text"
      },
      "source": [
        "*  <font color='blue'> <b>Create 30 samples </b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ec7MN6sL2BZ",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://i.imgur.com/p8eZaWL.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXlKWjCcBvTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use generating_samples function to create 30 samples \n",
        "# store these created samples in a list\n",
        "list_input_data =[]\n",
        "list_output_data =[]\n",
        "list_selected_row= []\n",
        "list_selected_columns=[]\n",
        "\n",
        "for i in range(0,30):\n",
        "  a,b,c,d = generating_samples(x,y)\n",
        "  list_input_data.append(a)\n",
        "  list_output_data.append(b)\n",
        "  list_selected_row.append(c)\n",
        "  list_selected_columns.append(d)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXUz9VFiMQkh",
        "colab_type": "text"
      },
      "source": [
        "<font color='cyan'> <b>Grader function - 2 </b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCvIq8NuMWOC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4af1066-8d46-455f-91e6-ea9e9126bea3"
      },
      "source": [
        "def grader_30(a):\n",
        "    assert(len(a)==30 and len(a[0])==506)\n",
        "    return True\n",
        "grader_30(list_input_data)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Pv-mkZkO6dh",
        "colab_type": "text"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whaHCPB0O8qF",
        "colab_type": "text"
      },
      "source": [
        "<font color='red'><b>Step - 2 </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBy4zXSWPtU8",
        "colab_type": "text"
      },
      "source": [
        "<font color='orange'><b>Flowchart for building tree</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xvH06HPQBdP",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://i.imgur.com/pcXfSmp.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRwPO_uHQjul",
        "colab_type": "text"
      },
      "source": [
        "*  <font color='blue'><b> Write code for building regression trees</b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWQp6tRwMthq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://stackoverflow.com/questions/4010840/generating-variable-names-on-fly-in-python\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "list_of_all_models=[]\n",
        "for i in range(1,31):\n",
        "  globals()['reg_tree_{}'.format(i)]=DecisionTreeRegressor(max_depth=None)\n",
        "  globals()['reg_tree_{}'.format(i)].fit(list_input_data[i-1],list_output_data[i-1])\n",
        "  list_of_all_models.append(globals()['reg_tree_{}'.format(i)])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21j8BKfAQ1U8",
        "colab_type": "text"
      },
      "source": [
        "<font color='orange'><b>Flowchart for calculating MSE </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q0mTBD2RBx_",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://i.imgur.com/sPEE618.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e-UamlHRjPy",
        "colab_type": "text"
      },
      "source": [
        "After getting predicted_y for each data point, we can use sklearns mean_squared_error to calculate the MSE between predicted_y and actual_y."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnIMT7_oR312",
        "colab_type": "text"
      },
      "source": [
        "*  <font color='blue'><b> Write code for calculating MSE</b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbGtkhtRb9Oy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "3623909e-d453-4826-d371-69293e6562bb"
      },
      "source": [
        "x[:,list_selected_columns[0]]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.3200e-03, 2.3100e+00, 0.0000e+00, ..., 1.5300e+01, 3.9690e+02,\n",
              "        4.9800e+00],\n",
              "       [2.7310e-02, 7.0700e+00, 0.0000e+00, ..., 1.7800e+01, 3.9690e+02,\n",
              "        9.1400e+00],\n",
              "       [2.7290e-02, 7.0700e+00, 0.0000e+00, ..., 1.7800e+01, 3.9283e+02,\n",
              "        4.0300e+00],\n",
              "       ...,\n",
              "       [6.0760e-02, 1.1930e+01, 0.0000e+00, ..., 2.1000e+01, 3.9690e+02,\n",
              "        5.6400e+00],\n",
              "       [1.0959e-01, 1.1930e+01, 0.0000e+00, ..., 2.1000e+01, 3.9345e+02,\n",
              "        6.4800e+00],\n",
              "       [4.7410e-02, 1.1930e+01, 0.0000e+00, ..., 2.1000e+01, 3.9690e+02,\n",
              "        7.8800e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWhcvMRWRA9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "array_of_Y=[]\n",
        "for i in range(1,31):\n",
        "  globals()['Y_{}'.format(i)]=globals()['reg_tree_{}'.format(i)].predict(x[:,list_selected_columns[i-1]])\n",
        "  array_of_Y.append(globals()['Y_{}'.format(i)])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VAxpNXEKS8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred=np.median(array_of_Y,axis=0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmHUarIBQHZT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa23e4a0-a950-4f06-bc92-482e5a8bf73b"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "mean_squared_error(y,y_pred)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.03934178743961356"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuclPDMnSz8F",
        "colab_type": "text"
      },
      "source": [
        "<font color='blue'><b>Step - 3 </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESb9FSIDTM5V",
        "colab_type": "text"
      },
      "source": [
        "<font color='orange'><b>Flowchart for calculating OOB score</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HB-d6NMETbd9",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://i.imgur.com/95S5Mtm.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WW3GOcFzTqbt",
        "colab_type": "text"
      },
      "source": [
        "Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBqcS03pUYSZ",
        "colab_type": "text"
      },
      "source": [
        "*  <font color='blue'><b> Write code for calculating OOB score </b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quvTZAQe3bzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mean(array):\n",
        "  return sum(array)/max(len(array),1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fog_6DNdS-h_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_oob=[]\n",
        "for i in range(len(x)): #looping boston whole dataset\n",
        "  y_oob_internal=[] #temporary arrays to hold oob value\n",
        "  for indx,j in enumerate(list_selected_row): # looping for all trees\n",
        "    if i not in j:   # calculating prediction value if ith point not in selected records of the particular model, \n",
        "      y_oob_internal.append(globals()['reg_tree_{}'.format(indx+1)].predict(x[i][list_selected_columns[indx]].reshape(1,-1))[0]) # appending predicted value y_oob_internal array\n",
        "  y_oob.append(np.median(y_oob_internal)) # calculating mean value returned by each model and appending to main array.\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32yW3iDj66jE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4317e50e-a6ed-4350-fd0c-25efc3f2e344"
      },
      "source": [
        "oob_score = sum((y-y_oob)*(y-y_oob))/len(y)\n",
        "oob_score"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17.062471590909087"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l340HBQOKKVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_oob=[]\n",
        "for i in range(len(x)): #looping boston whole dataset\n",
        "  y_oob_internal=[] #temporary arrays to hold oob value\n",
        "  for indx,j in enumerate(list_selected_row): # looping for all trees\n",
        "    if i not in j:   # calculating prediction value if ith point not in selected records\n",
        "      # print(\"i-->\",i,\"indx-->\",indx,\"reg_tree_{}\".format(indx),\"j-->\",sorted(j))\n",
        "      y_oob_internal.append(globals()['reg_tree_{}'.format(indx+1)].predict(x[i][list_selected_columns[indx]].reshape(1,-1))[0])\n",
        "      # print(\"cnt-->\",cnt,\"y_oob_internal-->\",y_oob_internal)\n",
        "  # print(mean(y_oob_internal))\n",
        "  y_oob.append(np.median(y_oob_internal))\n",
        "      # print(x[list_selected_row[indx+1]][:,list_selected_columns[indx+1]])\n",
        "# print(y_oob)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbuiwX3OUjUI",
        "colab_type": "text"
      },
      "source": [
        "# <font color='blue'><b>Task 2</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vKtKru0z_Qjh"
      },
      "source": [
        "*  <font color='blue'><b>Computing CI of OOB Score and Train MSE</b></font>\n",
        "  *   Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score </li>\n",
        "<li> After this we will have 35 Train MSE values and 35 OOB scores </li>\n",
        "<li> using these 35 values (assume like a sample) find the confidence intravels of MSE and OOB Score </li>\n",
        "<li> you need to report CI of MSE and CI of OOB Score </li>\n",
        "<li> Note: Refer the Central_Limit_theorem.ipynb to check how to find the confidence intravel</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceW5-D88Uswi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n=35"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQXBMZMBAvcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def task1(x,y):\n",
        "  # Use generating_samples function to create 30 samples \n",
        "  # store these created samples in a list\n",
        "  list_input_data,list_output_data,list_selected_row,list_selected_columns,list_of_all_models =[],[],[],[],[]\n",
        "  \n",
        "  for i in range(0,30):\n",
        "    a,b,c,d = generating_samples(x,y)\n",
        "    list_input_data.append(a)\n",
        "    list_output_data.append(b)\n",
        "    list_selected_row.append(c)\n",
        "    list_selected_columns.append(d)\n",
        "\n",
        "  # print(\"length of list_input_Data -->\",len(list_input_data))\n",
        "\n",
        "  for i in range(1,31):\n",
        "    # print(\"i value-->\",i)\n",
        "    globals()['reg_tree_task_{}'.format(i)]=DecisionTreeRegressor(max_depth=None)\n",
        "    globals()['reg_tree_task_{}'.format(i)].fit(list_input_data[i-1],list_output_data[i-1])\n",
        "    list_of_all_models.append(globals()['reg_tree_task_{}'.format(i)])\n",
        "\n",
        "  array_of_Y=[]\n",
        "  for i in range(1,31):\n",
        "    globals()['Y_{}'.format(i)]=globals()['reg_tree_task_{}'.format(i)].predict(x[:,list_selected_columns[i-1]])\n",
        "    array_of_Y.append(globals()['Y_{}'.format(i)])\n",
        "    \n",
        "  y_pred=np.median(array_of_Y,axis=0)\n",
        "  mse=mean_squared_error(y,y_pred)\n",
        "\n",
        "\n",
        "  y_oob=[]\n",
        "  for i in range(len(x)):\n",
        "    y_oob_internal=[] \n",
        "    for indx,j in enumerate(list_selected_row):\n",
        "      if i not in j:\n",
        "        y_oob_internal.append(globals()['reg_tree_task_{}'.format(indx+1)].predict(x[i][list_selected_columns[indx]].reshape(1,-1))[0]) # appending predicted value y_oob_internal array\n",
        "    y_oob.append(mean(y_oob_internal)) # calculating mean value returned by each model and appending to main array.\n",
        "\n",
        "  oob_score=sum((y-y_oob)*(y-y_oob))/len(y)\n",
        "\n",
        "  return (mse,oob_score)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o77ywjmqJtDV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "1b2ddcbf-fb93-4f43-e2a0-e55174dc8048"
      },
      "source": [
        "%time\n",
        "mse_array,oob_score_array=[],[]\n",
        "for i in range(0,35):\n",
        "  mse,oob_score=task1(x,y)\n",
        "  mse_array.append(mse)\n",
        "  oob_score_array.append(oob_score)\n",
        "print(mse_array)\n",
        "print(oob_score_array)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 4.77 µs\n",
            "[0.01287549407114624, 0.05558423913043482, 0.10437687698702999, 0.35164904380419953, 0.017802618577075095, 0.0697929828211052, 0.06106555237378219, 0.0738599308300395, 0.20410079051383406, 0.2090760869565217, 0.15669156846240195, 0.08880505491090893, 0.0789772727272726, 0.04942811264822135, 0.011946640316205556, 0.2354523838932806, 0.2973475941760103, 0.14908596837944665, 0.0653853754940711, 0.11380324989020649, 1.0139871541501977, 0.06480786122090475, 0.0242193675889328, 0.15518635265700484, 0.13016798418972336, 0.03264822134387353, 0.10997077294685989, 0.19801054359520068, 0.06153162055335971, 0.2963154644268776, 0.03576086956521736, 0.033071353632947824, 0.07804471343873516, 0.07243715555117983, 0.009925508201836407]\n",
            "[15.143005946566982, 15.369863971659495, 14.879458362664652, 17.453214987193288, 14.209457268156738, 14.70388138502152, 14.546084144202032, 15.968659606342484, 16.18501876700133, 13.645164956245809, 14.56098489375347, 19.06346701020754, 13.924182509950898, 14.289314633744917, 12.613104516207125, 16.55790021783861, 15.889290157977056, 16.212295045179744, 14.067240503475617, 10.821545933897522, 16.68524416332194, 15.854435717282628, 13.162711509963396, 18.414103620190097, 18.440252835308804, 13.558321299607151, 14.649611470271678, 15.503877163466585, 17.651889608206638, 18.438513160238045, 14.405140173829455, 11.944570773503669, 13.400370904493924, 14.730410213586598, 16.388907328558528]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1FuSnN_J7pB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c1628d63-c6a1-47a0-fa1b-ce310af8c865"
      },
      "source": [
        "# ref: https://www.mathsisfun.com/data/confidence-interval.html\n",
        "from statistics import stdev\n",
        "mean_mse = mean(mse_array)\n",
        "stddev_mse = stdev(mse_array)\n",
        "mean_oob = mean(oob_score_array)\n",
        "stddev_oob = stdev(oob_score_array)\n",
        "print(\"95% Confidence interval for MSE is:{} {}\".format(mean_mse-(2*(stddev_mse/np.sqrt(n))),mean_mse+(2*(stddev_mse/np.sqrt(n)))))\n",
        "print(\"95% Confidence interval for OOB is: {} {} \".format(mean_oob-(2*(stddev_oob/np.sqrt(n))),mean_oob+(2*(stddev_oob/np.sqrt(n)))))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "95% Confidence interval for MSE is:0.07535645914062827 0.19454021400371707\n",
            "95% Confidence interval for OOB is: 14.59665986995849 15.879425544848132 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKTnJdiBVS_e",
        "colab_type": "text"
      },
      "source": [
        "# <font color='blue'><b>Task 3</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXxrvZqHV1Fr",
        "colab_type": "text"
      },
      "source": [
        "<font color='orange'><b>Flowchart for Task 3</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyjwEJ62V6a6",
        "colab_type": "text"
      },
      "source": [
        "<b>Hint: </b> We created 30 models by using 30 samples in TASK-1. Here, we need send query point \"xq\"  to 30 models and perform the regression on the output generated by 30 models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0emSwLL7VurD",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://i.imgur.com/Y5cNhQk.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29hjwKlWWDfo",
        "colab_type": "text"
      },
      "source": [
        "*  <font color='blue'><b> Write code for TASK 3 </b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kil5sQ9xbtO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "2e2ca6d1-96e1-4a3b-c175-626dc9463375"
      },
      "source": [
        "xq=np.array([0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60])\n",
        "xq.reshape(1,-1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.8000e-01, 2.0000e+01, 5.0000e+00, 0.0000e+00, 4.2100e-01,\n",
              "        5.6000e+00, 7.2200e+01, 7.9500e+00, 7.0000e+00, 3.0000e+01,\n",
              "        1.9100e+01, 3.7213e+02, 1.8600e+01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_pUlSD-VYD1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d71167f-d4c6-46cb-88d8-eafe0229c7e4"
      },
      "source": [
        "xq=np.array([0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60])\n",
        "yq=[]\n",
        "for i in range(1,31):\n",
        "  globals()['yq_{}'.format(i)]=globals()['reg_tree_{}'.format(i)].predict(xq[list_selected_columns[i-1]].reshape(1,-1))\n",
        "  yq.append(globals()['yq_{}'.format(i)])\n",
        "np.median(yq)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOdUi-0xWOJ9",
        "colab_type": "text"
      },
      "source": [
        "<font color='red'><b>Write observations for task 1, task 2, task 3 indetail</b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIcax45hWKT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXY5bHffqx-1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}